#include "02positional_embedding.h"
#include "position_lookup.h"
#include "tensor_add.h"
#include "model_config.h"
#include <stdio.h>


// 创建位置编码结构
// encodings tensor shape: [max_seq_length, encoding_dim]
PositionalEncoding* positional_encoding_create(int max_seq_length, int encoding_dim) {
    PositionalEncoding* pos_enc = (PositionalEncoding*)malloc(sizeof(PositionalEncoding));
    if (!pos_enc) {
        fprintf(stderr, "Failed to allocate memory for positional encoding\n");
        return NULL;
    }

    // 初始化基本参数
    pos_enc->max_seq_length = max_seq_length;
    pos_enc->encoding_dim = encoding_dim;
    const int batch_size = g_model_config.batch_size;

    // 创建位置编码张量 [batch_size, max_seq_length, encoding_dim]
    int shape[] = {batch_size, max_seq_length, encoding_dim};
    pos_enc->encodings = tensor_create(shape, 3);
    if (!pos_enc->encodings) {
        free(pos_enc);
        return NULL;
    }

    // 计算位置编码
    if (!compute_positional_encodings(pos_enc->encodings, batch_size, max_seq_length, encoding_dim)) {
        tensor_free(pos_enc->encodings);
        free(pos_enc);
        return NULL;
    }

    return pos_enc;
}

void free_positional_encoding(PositionalEncoding* pos_enc) {
    if (pos_enc) {
        tensor_free(pos_enc->encodings);
        free(pos_enc);
    }
}

// positional_encoding forward pass
// input tensor shape: [batch_size, seq_length, encoding_dim], encoding_dim is the same as embedding_dim, d_model, generated by token_embedding_forward
// adds positional encoding directly to input tensor, shape remains the same
bool positional_encoding_forward(const PositionalEncoding* pos_enc, Tensor* input) {
    if (input->num_dims != 3) {
        fprintf(stderr, "Input tensor must be 3-dimensional [batch_size, seq_length, encoding_dim]\n");
        return false;
    }

    int batch_size = input->shape[0];
    int seq_length = input->shape[1];
    int encoding_dim = input->shape[2];

    if (encoding_dim != pos_enc->encoding_dim) {
        fprintf(stderr, "Encoding dimension mismatch\n");
        return false;
    }

    // 确保序列长度不超过最大长度
    if (seq_length > pos_enc->max_seq_length) {
        seq_length = pos_enc->max_seq_length;
    }

    // 使用tensor_add直接进行张量加法
    return tensor_add(input, pos_enc->encodings, input);
}